# Core dependencies for Lecture Transcriber

# Audio processing
ffmpeg-python>=0.2.0
librosa>=0.10.0

# Hugging Face ecosystem for Whisper and LLM models (unified approach)
transformers>=4.30.0
torch>=2.0.0
torchaudio>=2.0.0
tokenizers>=0.13.0
accelerate>=0.20.0

# GPU acceleration support (user-configurable)
# Install based on your hardware:
# For NVIDIA GPUs: pip install torch[cuda] torchaudio[cuda]
# For AMD GPUs: pip install torch[rocm] torchaudio[rocm]  
# For Apple Silicon: torch and torchaudio automatically use Metal Performance Shaders

# LLM integration
huggingface-hub>=0.16.0
requests>=2.31.0

# Additional dependencies for specific models
sentencepiece>=0.1.99  # For some tokenizers
protobuf>=3.20.0       # For model serialization
safetensors>=0.3.0     # For safe model loading

# Data processing
numpy>=1.24.0
pandas>=2.0.0
pydantic>=2.0.0

# File handling and utilities
pyyaml>=6.0
click>=8.1.0
rich>=13.0.0
tqdm>=4.65.0

# GPU acceleration (optional but recommended)
# Uncomment if you have CUDA-capable GPU:
# torch[cuda]>=2.0.0
# torchaudio[cuda]>=2.0.0

# Testing dependencies
pytest>=7.4.0
pytest-cov>=4.1.0
hypothesis>=6.82.0  # For property-based testing (17 properties defined)

# Development dependencies (code quality and formatting)
black>=23.0.0      # Code formatting
flake8>=6.0.0      # Linting
mypy>=1.5.0        # Type checking